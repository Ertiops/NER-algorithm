{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fce1437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "nlp_ner = spacy.load(\"/bionalizer/model-last\") # NER-модель\n",
    "nlp = spacy.load('ru_core_news_lg') # Модель для лемматизации токенов в терминах\n",
    "\n",
    "document = \"ввести название текста\"\n",
    "\n",
    "list_of_strings = [i.strip().lower() for i in open(f'{document}.txt', 'r', encoding='utf-8').readlines()]\n",
    "\n",
    "# создание списка кандидатов в термины\n",
    "\n",
    "terms = []\n",
    "\n",
    "for i in list_of_strings:\n",
    "    doc = nlp_ner(i)\n",
    "    for ent in doc.ents:\n",
    "        terms.append(ent.text)\n",
    "\n",
    "# лемматизация кандидатов в термины\n",
    "        \n",
    "lemmatized_collocations = []\n",
    "\n",
    "for i in terms:\n",
    "    doc = nlp(i)\n",
    "    lemmatized_term = []\n",
    "    for j in doc:\n",
    "         lemmatized_term.append(j.lemma_)\n",
    "            \n",
    "    lemmatized_term = \" \".join(lemmatized_term)\n",
    "    lemmatized_collocations.append(lemmatized_term)\n",
    "\n",
    "# подсчет токенов терминов для параметра Доля терминов   \n",
    "    \n",
    "terms_tokens = 0\n",
    "\n",
    "for i in lemmatized_collocations:\n",
    "    terms_tokens += len(i.split())    \n",
    "  \n",
    "# подсчет унеикальных терминов\n",
    "\n",
    "unique_terms = {}\n",
    "\n",
    "for i in lemmatized_collocations:\n",
    "    if i not in unique_terms:\n",
    "        unique_terms[i] = 1\n",
    "    else:\n",
    "        unique_terms[i] += 1\n",
    "\n",
    "# создание структур данных терминов по алфавиту и частотности\n",
    "        \n",
    "terms_frequency = {k: unique_terms[k] for k in sorted(unique_terms, key=unique_terms.get, reverse=True)}\n",
    "terms_alphabet = dict(sorted(unique_terms.items(), key=lambda x: x[0]))\n",
    "\n",
    "\n",
    "di = {\"термин\": terms_frequency.keys(), \"частотность\":  terms_frequency.values()}\n",
    "z = pd.DataFrame(di)\n",
    "\n",
    "dy = {\"термины по алфавиту\": terms_alphabet.keys()}\n",
    "y = pd.DataFrame(dy)\n",
    "\n",
    "# запись списков терминов по алфавиту и частотности в excel-файл\n",
    "\n",
    "z.to_excel(f\"{document}_alphabet.xlsx\")\n",
    "y.to_excel(f\"{document}_frequency.xlsx\")\n",
    "\n",
    "# статистический блок\n",
    "\n",
    "print(\"количество терминов:\", len(lemmatized_collocations))\n",
    "print(\"токены терминов:\", terms_tokens)\n",
    "print(\"количество уникальных терминов:\", len(unique_terms)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
